web apis with rack/sinatra and mongodb

example application is a location beat - topical!

set - client side is very simple, you have a handset and an application id. handset is unique within the context of the application id. theres a map between the handset id and some concrete identifying features of the handset, so we can check for changes in the hardware and disable. So there’s a registration thing going on.

app id, app name, app version, app owner

handset gets registered, handset starts broadcasting, we start storing - lat, long, alt, accu, time, handset

what do we need to handle

* authentication - are you the right handset
* flooding - crazy client is crazy
* scale - minimal response time for synchronous protocol

technology contents - rack, sinatra, mongodb

why? rack is a good standard, sinatra is easy to use, mongodb just because!

I was thinking of redis here - keeping a list thereof, but insert some reason for choosing mongo instead and link up to it.

Let’s design the API.

what are the conditions a good API?  focussed. short. bandwidth-savvy. resilient. evolution strategy.

this one is going to be easy.

 ping (lat, long, alt, accu, handset)
 track (starttime, period, handset)

that’s focussed and short.

Note we don’t have anything that establishes a session. Why - because we don’t need it. Pass
the handset id with each request, and the auth is done on the server. If the handsetid is not 
registered, then we drop the request.

We’ll use some rack middleware for that. 

Hang on - what if the device changes? At random intervals, we’ll put a challenge to the device. Send
me your stuff. So when it does a ping, we’ll send a return code that indicates that. Then we need another
API call

register(handset, details)

that will register a handset for use and authentication.

Bandwidth savvy means that we don’t pile on lots of data. latency savvy means we don’t chop the data up too small. Middle ground is required and this really means you have to look at the application usage. Here where we are there isn’t a specific user interaction, so the latency isn’t an issue really (no-one sees a slow-down), and the amount of data is small, sent at appropriate intervals, so the bandwidth is not hogged.

But - we’ve no control over the behaviour of the clients - what if one of them goes nuts and starts to DoS the server? There’s a middleware for that:  rack_throttle. This gives us a number of options on how we can structure the access - per interval, number of invocations, etc 

(include examples here)

resilience means stability of behaviour in the presence of badness. if there is weird data thrown at us, for example, or someone attempts to hog a connection. We cope with weird data by rejecting stuff that is large, and by picking out just what we need from the payloads.

an evolution strategy is something that you need if you want the service to live through API changes. There’s lots of ways to solve this, from subtle to blatant, and it’s ok to just hit this with a hammer and put a version in the URL

  POST /api/1.0/ping

for example. Lots of services do this already (cite examples). To go with this you just need a compatibility statement - what the 1.0 means and what it means for your users to go to 1.1, or 2.0, for example. Stick to this or you will definitely piss people off.

Let’s go an set this up!

MONGO - go here and get this set up. if you are using a mac,
 there’s a neat client called MongoHub which I use to see what’s
going on the database.

Being the land of ruby, we are rosily suffused with choice of support
for mapping objects to the Mongo DB.
Mongoid. MongoMapper. Mongomatic. MongoModel.

http://mongoid.org/
http://mongomapper.com/
http://mongomatic.com/
http://www.mongomodel.org/documents

http://www.slideshare.net/drumwurzel/practical-ruby-projects-with-mongo-db
http://www.slideshare.net/sbeam/no-sql-no-problem-using-mongodb-in-ruby
http://www.slideshare.net/pengwynn/mongodb-ruby-document-store-that-doesnt-rhyme-with-ouch
http://www.slideshare.net/pengwynn/hands-on-with-ruby-mongodb
http://www.slideshare.net/jnunemaker/mongodb-grand-rapids-rug
http://www.slideshare.net/kidpollo/mongo-mapper
http://www.slideshare.net/ihower/designing-ruby-apis
http://www.slideshare.net/benschwarz/sinatra-rack-and-middleware-1509268

I kinda liked mongomapper better because of the way it
does indexes and embedded models. So lets go for that (maybe 
some more research here for the crew).

Before we write any code, let’s take a look at what is going to go
into the database.

A -> database content

NOW Let’s write some code!

1. The API, in sinatra.

Why do we want to version. This is important. You may think it’s
a little fussy - but you are making an API to have developer 
consumers, not just for laughs. YOU need to control the lifecycle
of the API - it doesn’t control you. That’s what versioning is
for - it allows you to add and remove capabilities, while keeping
the consumers informed. Usually, you would have a compatibility
statement somewhere in the docs - so for example you only break
compatibility on major version number increments - that’s where
deprecations get cut out. Minor version increments are expected
to be backward compatible - but not forward compatible, so a
1.4 server should work with a 1.2 client, but not necessarily v.v.
so we check.

configure do
  MAJOR_VERSION = 1
  MINOR_VERSION = 0
end

helpers do
  def version_compatible?(nums)
    return MAJOR_VERSION == nums[0].to_i && MINOR_VERSION >= nums[1].to_i
  end
end

before %r{/api/v(\d)\.(\d)} do
  if version_compatible?(params[:captures])
    target = request.fullpath.split('/').last
    request.path_info = "/#{target}"
  else
    halt 400, "Version not compatible with this server"
  end
end

So this approach just detects incompatible version expectations 
from the client. Using Rack, you can do more, by routing the 
requests to a correctly versioned server. We’ll look at that
later (TBD)

1.5 Let’s write a test to check versioning.

DONE.
TBD: TAG AT THIS POINT

2. Plugging it into the Mongo.

http://www.viget.com/extend/getting-started-with-mongodb-mongomapper/
http://railstips.org/blog/archives/2009/06/03/what-if-a-key-value-store-mated-with-a-relational-database-system/   --> GOOD INTRO

3. Let’s write a test.

Talk about putting an index on the handset

DONE.
TBD: TAG AT THIS POINT

rack_throttle_branch now.

3.5 Let's write the functionality now shall we?

We're going to collect a chunk of data, potentially a large amount. Do we
want to have a years worth of data for a handset? Perhaps not. Maybe only
the last month or so will be enough - let's say 90 days. We want to have 
a moving window of 90 days worth of location pings. We can tune that later
as we look into the issue of database size. 

CAPPED COLLECTION IS A BUST FOR HERE

In any case, mongo gives us a real boost here by providing the concept
of a Capped Collection.
I had started off with sinatra/mongomapper - but don't really need it,
it just makes the 'set; stuff look nice

We'll cap the collection at oooh 2MB. 

MongoMapper.database.create_collection(:locations, {:capped => true, :size => 2097152})


http://www.mongodb.org/display/DOCS/Capped+Collections

This is a fixed-size collection that has a high-performance way of
throwing out old entries - and it maintains insertion order, so it's
just the job for this kind of logging work.

I don't need to add an index, because this is more writes than
reads - capped collections work best with no indices. Note also
that capped collectiosn are not shardable.

We're going to model the Location as an EmbeddedDocument - this is 
a kind of a containment relationship - a belongs_to is perhaps the
nearest relation in rails etc and you can see in the model code
where this is added 'many locations'. Actually, this turns out to
be not quite right for us -- an embedded document is put into another
document, not in a collection of its own..

The learning experience of mongo:..

"The key question in Mongo schema design is "does this object merit its own collection, or rather should it embed in objects in other collections?""

Lets write a test first and get it to pass.

Point out the place where the Dynamic Queries a la rails have
been included...


http://datagraph.rubyforge.org/rack-throttle/

4. Let’s write another test, this time, to simulate a mad client

5. Let’s configure Rack::Throttle now to stop the madness

Rack throttle has a number of approachs to throttling, and we 
can limit an interval between invocations and the number of 
invocations per hour. Once a client (as identified by IP) goes
over this amount, then its 403'd. 

I'm going to limit clients to an interval - once location update
every 5 minutes. If we just blast in there and set this interval,
it will be across the board, so we need to tell Rack::Throttle 
that it is to only look @ the 'plink' API call.

We should store the rate counts in memcached or redis - if 
we are going to have many of these guys running, they will
need to share the rate counts! Note - make a mongo adapter
for rack/throttle!

TAG AT THIS POINT

{  CUT THIS.
    6. No authentication here - let’s do that now with Rack::Warden
    and a custom authentication thingie.

    7. Let’s put in a test for that. Yay!
}

{ CUT THIS
    8. So where are we. We haven’t done the ‘handset hardware change’ bit.

    The hardware change means that we (sometimes) detect when
    the DNA of the handset has changed. We change the code of the
    hadnset to do this

    9. Let’s write a test.

    10. ok now let’s put the code in.

TAG AT THIS POINT
}

Only three things are left, I think. 1) some way to look at all the 
handsets and the updates! and 2) an actual handset client to run 
against it and 3) somewhere on the webs to put the damn thing.

1. Let’s make a web page then that you can select a handset and
then you can see a map of everywhere that the handset has pinged 
from. We can put this in the sinatra too, or we can Rack mount 
another little application to do it. Of course, the google is 
absolutely necessary for this!

We need to switch to the modular style of sinatra.

Now create a new app 

Updated the rack starter script
  
Now - lookee here - there's a place where we could think
about versioning here as well..

map '/api' do
  map '/v1.3' do
    run PlinkApp
  end

  map '/latest' do
    run PlinkApp
  end
end


TBD:
   *  Make sure that the JS etc can all be found - change layout relative paths
   *  create a list of handsets, which are linked to handset pages
   *  show the location blobs as lots of map things, maybe.
   *  publish to heroku
   * SLIDES SLIDES SLIDES.
   
TAG AT THIS POINT 

2. Ok, let’s write an iOS client. Ok, let’s not - here’s one I
made earlier! (simulator)

3. Where o where are we going to put this. The two places I’d 
look at right now are heroku and cloudfoundry. Heroku is the one
that I’m used to, but cloudfoundry can do it too, so maybe we 
can take a quick look at both!

520% heroku create plink
Creating plink.... done
http://plink.heroku.com/ | git@heroku.com:plink.git
Git remote heroku added
521% heroku addons:add mongohq:free
Adding mongohq:free to plink... done (free)
522% heroku addons:add memcache:5mb
Adding memcache:5mb to plink... done (free)

http://railsillustrated.com/blazing-fast-sinatra-with-memcached.html

Now update the throttler to use memcached - this is easy enough!

http://kplawver.posterous.com/date-range-queries-with-mongomapper

Using rest client to do a quick test
irb(main):001:0> require 'rest_client'
=> true
irb(main):004:0> require 'json'
=> true
irb(main):005:0> RestClient.put "http://localhost:9292/register", { 'dna' => "Hey!" }.to_json
=> "8f1b7281910cec35deb4792c704f67efb8d4c608a5876ce1dc05f40589b7087f69757e236cb506967cb38479cef26db2eebaabd16c8a4fb1aafca19940fea9cb"


bundles
  rack throttle
  sinatra
  mongomapper
  
